[project]
name = "aidocumentindexer-backend"
version = "0.1.0"
description = "AI-powered document indexing and RAG system"
requires-python = ">=3.11"
license = { text = "MIT" }
authors = [
    { name = "AIDocumentIndexer Team" }
]
keywords = ["ai", "rag", "document-indexing", "llm", "fastapi"]

dependencies = [
    # Core Framework (Phase 87: upper bounds on critical deps)
    "fastapi>=0.109.0,<1.0.0",
    "uvicorn[standard]>=0.27.0,<1.0.0",
    "pydantic>=2.5.0,<3.0.0",
    "pydantic-settings>=2.1.0,<3.0.0",
    "python-multipart>=0.0.6",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",
    "httpx>=0.26.0",
    # Database (Phase 87: upper bounds on critical deps)
    "sqlalchemy>=2.0.25,<3.0.0",
    "alembic>=1.13.0,<2.0.0",
    "asyncpg>=0.29.0",
    "psycopg2-binary>=2.9.9",
    "pgvector>=0.2.4",
    "greenlet>=3.0.0",
    "aiosqlite>=0.19.0",
    "aiomysql>=0.2.0",
    "sqlparse>=0.4.4",
    # LLM & RAG (pinned to 0.3.x for stability)
    "langchain>=0.3.0,<1.0.0",
    "langchain-community>=0.3.0,<1.0.0",
    "langchain-core>=0.3.0,<1.0.0",
    "langchain-openai>=0.2.0,<1.0.0",
    "langchain-litellm>=0.1.0",
    "langgraph>=0.2.0,<1.0.0",
    "litellm>=1.50.0",
    # Embeddings
    "sentence-transformers>=2.2.2",
    "tiktoken>=0.5.2",
    "transformers>=4.45.0", # Phase 68: Required for Qwen3 Embedding
    "torch>=2.1.0", # Phase 68: Required for Qwen3 Embedding
    "google-genai>=1.0.0", # Phase 87: Unified Google GenAI SDK (replaces deprecated google-generativeai)
    "faiss-cpu>=1.8.0", # Phase 68: FAISS index for semantic cache O(log n) search
    # Local Vector Store
    "chromadb>=0.5.0",
    # Document Processing - PDF
    "pymupdf>=1.23.0",
    "pypdf>=3.17.0",
    # Document Processing - Office
    "python-pptx>=0.6.23",
    "python-docx>=1.1.0",
    "mammoth>=1.6.0", # DOCX to HTML conversion for preview
    "openpyxl>=3.1.2",
    # Document Processing - Universal
    "unstructured[pdf,docx,pptx,xlsx]>=0.12.0",
    # OCR
    "paddlepaddle>=2.6.0",
    "paddleocr>=2.7.0",
    "pillow>=10.2.0",
    # File type detection
    "python-magic>=0.4.27",
    "filetype>=1.2.0",
    # Email parsing
    "extract-msg>=0.48.0",
    "email-validator>=2.1.0",
    # Ray (Distributed Processing) - Phase 87: updated to 2.10+ for better async/memory mgmt
    "ray[default]>=2.10.0,<3.0.0",
    # Web Scraping
    "crawl4ai>=0.8.0",
    "beautifulsoup4>=4.12.0",
    "lxml>=5.1.0",
    # Caching & Sessions
    "redis>=5.0.0",
    "hiredis>=2.3.0",
    # Task Queue
    "celery[redis]>=5.3.6",
    # File Watching
    "watchdog>=3.0.0",
    # Document Generation
    "reportlab>=4.0.0",
    "weasyprint>=60.0",
    "jinja2>=3.1.0",
    # Utilities
    "python-dotenv>=1.0.0",
    "aiofiles>=23.2.0",
    "tenacity>=8.2.0",
    "structlog>=24.1.0",
    "orjson>=3.9.0",
    "numpy>=1.26.0",
    "pandas>=2.1.0",
    "pyjwt>=2.10.1",
    "langchain-text-splitters>=0.3.0,<1.0.0",
    "pytesseract>=0.3.13",
    "langchain-anthropic>=0.3.22",
    "bcrypt<4.1",
    "unidecode>=1.4.0",
    "edge-tts>=7.2.7",
    "hnswlib>=0.8.0",
    "sentry-sdk[fastapi]>=1.40.0",
    "prometheus-client>=0.19.0",
    "motor>=3.3.0",
    "ragatouille>=0.0.9.post2",
    "chonkie>=1.5.2",
    "docling>=2.69.1",
    "cartesia>=2.0.17",
    "websockets>=15.0.1",
    "cohere>=5.20.1",
    "dspy-ai>=3.1.2",
    "instructor>=1.14.4",
    "gptcache>=0.1.44",
    "cachetools>=6.2.2",
    "httptools>=0.7.1",
    "voyageai>=0.3.7",
    "elevenlabs>=2.31.0",
    "colpali-engine>=0.3.13",
    "rank-bm25>=0.2.2",
    "rapidfuzz>=3.0.0", # Fast fuzzy string matching for entity resolution
    "fastembed>=0.7.4",
    "pdf2image>=1.17.0",
    # Note: surya-ocr removed due to dependency conflict with fastembed
    # VisionDocumentProcessor uses tesseract or claude for OCR instead
    "langchain-ollama>=0.3.10",
    "cython>=3.2.4",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=4.1.0",
    "black>=24.1.0",
    "ruff>=0.1.0",
    "mypy>=1.8.0",
]
# Advanced TTS providers (experimental, may require GPU)
# Note: These packages may need to be installed from source:
# - chatterbox-tts: pip install git+https://github.com/resemble-ai/chatterbox.git
# - cosyvoice: pip install git+https://github.com/FunAudioLLM/CosyVoice.git
# The TTS service gracefully falls back to HTTP API if packages are not installed
tts-advanced = [
    # Uncomment when packages are available on PyPI:
    # "chatterbox-tts>=0.1.0",
    # "cosyvoice>=0.1.0",
]
# Cloud storage and collaboration connectors
connectors = [
    "slack-sdk>=3.20.0",
    "pygithub>=2.1.0",
    "dropbox>=11.36.0",
    "boxsdk>=3.9.0",
]
# Performance optimizations (Phase 2-4)
# - numba: JIT compilation for numerical hot loops (5-100x speedup)
# - datasketch: MinHash/LSH for O(n) approximate deduplication
# - scipy: Additional vectorized operations (cdist, etc.)
# - cython: Compiled extensions for 10-100x speedup (compiles at server start)
performance = [
    "numba>=0.58.0",
    "datasketch>=1.6.0",
    "scipy>=1.11.0",
    "cython>=3.0.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["api", "services", "db", "langchain_ext", "processors", "ray_workers"]

[tool.uv]
dev-dependencies = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=4.1.0",
    "black>=24.1.0",
    "ruff>=0.1.0",
    "mypy>=1.8.0",
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short"
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::UserWarning",
]

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]
ignore = ["E501"]

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.mypy]
python_version = "3.11"
strict = false
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = false
