# =============================================================================
# AIDocumentIndexer - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control!
# =============================================================================

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
APP_NAME=AIDocumentIndexer
APP_ENV=development
# Options: development | staging | production

# Secret key for JWT tokens and encryption (min 32 characters)
SECRET_KEY=your-super-secret-key-change-this-in-production

# API URL (for frontend to connect to backend)
API_URL=http://localhost:8000

# Frontend URL
FRONTEND_URL=http://localhost:3000

# Debug mode (set to false in production)
DEBUG=true

# Development mode - enables dev token bypass for authentication
# WARNING: Never enable in production!
DEV_MODE=true

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# Database type: postgresql | sqlite | mysql
DATABASE_TYPE=postgresql

# PostgreSQL (recommended for production)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/aidocindexer

# SQLite (for development/testing)
# DATABASE_URL=sqlite:///./aidocindexer.db

# MySQL (alternative)
# DATABASE_URL=mysql://user:password@localhost:3306/aidocindexer

# Connection pool settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10

# =============================================================================
# VECTOR STORE CONFIGURATION
# =============================================================================
# Vector store backend: pgvector | chroma | auto
# - pgvector: PostgreSQL + pgvector extension (recommended for production)
# - chroma: ChromaDB local storage (no server required, good for development)
# - auto: Automatically detect based on DATABASE_URL (SQLite → chroma, PostgreSQL → pgvector)
VECTOR_STORE_BACKEND=auto

# ChromaDB settings (when using chroma backend)
# Directory for persistent storage
CHROMA_PERSIST_DIRECTORY=./data/chroma
# Collection name for documents
CHROMA_COLLECTION_NAME=documents

# =============================================================================
# LLM PROVIDERS
# =============================================================================

# -----------------------------------------------------------------------------
# OpenAI (Primary cloud provider)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI organization (optional)
OPENAI_ORGANIZATION=

# OpenAI model settings
OPENAI_CHAT_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# Ollama (Local LLM)
# -----------------------------------------------------------------------------
# Enable Ollama integration
OLLAMA_ENABLED=true

# Ollama server URL
OLLAMA_HOST=http://localhost:11434

# Default Ollama model
OLLAMA_CHAT_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# -----------------------------------------------------------------------------
# Anthropic Claude (Optional)
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# -----------------------------------------------------------------------------
# Default LLM Settings
# -----------------------------------------------------------------------------
# Which provider to use by default: openai | ollama | anthropic
DEFAULT_LLM_PROVIDER=openai

# Default models (can be overridden per task)
DEFAULT_CHAT_MODEL=gpt-4o
DEFAULT_EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimension (must match your embedding model)
EMBEDDING_DIMENSION=1536

# Temperature for chat responses (0.0 - 2.0)
DEFAULT_TEMPERATURE=0.7

# Max tokens for responses
DEFAULT_MAX_TOKENS=4096

# =============================================================================
# RAY CLUSTER CONFIGURATION
# =============================================================================
# Ray address: "auto" for local, or "ray://head-node:10001" for cluster
RAY_ADDRESS=auto

# Number of CPUs to use (leave empty for auto-detect)
RAY_NUM_CPUS=4

# Number of GPUs (if available)
RAY_NUM_GPUS=0

# Ray dashboard port
RAY_DASHBOARD_PORT=8265

# Object store memory (bytes, e.g., 2000000000 for 2GB)
RAY_OBJECT_STORE_MEMORY=

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# Storage type: local | s3
STORAGE_TYPE=local

# Local storage path
STORAGE_PATH=/app/storage

# S3 Configuration (if STORAGE_TYPE=s3)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1
AWS_S3_BUCKET=aidocindexer-files

# Maximum file size for upload (in bytes, default 500MB)
MAX_UPLOAD_SIZE=524288000

# =============================================================================
# AUTHENTICATION
# =============================================================================
# NextAuth secret (generate with: openssl rand -base64 32)
NEXTAUTH_SECRET=your-nextauth-secret-here

# NextAuth URL (your frontend URL)
NEXTAUTH_URL=http://localhost:3000

# Session expiry (in seconds, default 24 hours)
SESSION_EXPIRY=86400

# Default admin credentials (change immediately after first login!)
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=changeme123

# =============================================================================
# DOCUMENT PROCESSING
# =============================================================================
# Processing mode: full | smart | text_only
DEFAULT_PROCESSING_MODE=smart

# Chunk size for text splitting (tokens)
CHUNK_SIZE=512

# Chunk overlap (percentage)
CHUNK_OVERLAP=0.15

# OCR language (comma-separated for multiple)
OCR_LANGUAGES=en,de

# Enable image optimization
ENABLE_IMAGE_OPTIMIZATION=true

# Maximum image dimension (pixels) - larger images will be resized
MAX_IMAGE_DIMENSION=2048

# Skip images smaller than this (pixels) - likely decorative
MIN_IMAGE_DIMENSION=50

# =============================================================================
# RAG & SEARCH SETTINGS
# =============================================================================
# Query expansion (improves retrieval by 8-12%)
# Generates paraphrased versions of queries to improve recall
ENABLE_QUERY_EXPANSION=true

# Number of query variations to generate (1-5)
QUERY_EXPANSION_COUNT=2

# Document summarization for large files
# Reduces embedding tokens by 30-40% for documents over threshold
ENABLE_SUMMARIZATION=true

# Minimum document size (tokens) to trigger summarization
SUMMARIZATION_THRESHOLD=10000

# Self-RAG verification for answer quality
ENABLE_VERIFICATION=true

# Verification level: none | quick | standard | thorough
VERIFICATION_LEVEL=quick

# Similarity threshold for vector search (0.0-1.0)
# Lower for OCR'd documents (0.4), higher for clean text (0.7)
SIMILARITY_THRESHOLD=0.4

# Default number of results to retrieve
DEFAULT_TOP_K=5

# =============================================================================
# OPTIONAL FEATURES
# =============================================================================

# -----------------------------------------------------------------------------
# File Watcher
# -----------------------------------------------------------------------------
# Enable automatic file watching
ENABLE_FILE_WATCHER=false

# Directories to watch (comma-separated)
WATCH_DIRECTORIES=/path/to/watch1,/path/to/watch2

# Default access tier for auto-indexed files
WATCH_DEFAULT_TIER=30

# -----------------------------------------------------------------------------
# Web Scraping
# -----------------------------------------------------------------------------
# Enable web scraping feature
ENABLE_WEB_SCRAPING=true

# Maximum pages to scrape per request
MAX_SCRAPE_PAGES=10

# Scraping timeout (seconds)
SCRAPE_TIMEOUT=30

# -----------------------------------------------------------------------------
# Multi-LLM Collaboration
# -----------------------------------------------------------------------------
# Enable multi-LLM collaboration mode
ENABLE_MULTI_LLM=true

# Minimum tier level to use multi-LLM feature
MULTI_LLM_MIN_TIER=50

# =============================================================================
# REDIS (Caching & Sessions)
# =============================================================================
REDIS_URL=redis://localhost:6379/0

# Cache TTL (seconds)
CACHE_TTL=3600

# =============================================================================
# LOGGING
# =============================================================================
# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Log format: json | text
LOG_FORMAT=text

# Log file path (leave empty for stdout only)
LOG_FILE=

# =============================================================================
# RATE LIMITING
# =============================================================================
# Requests per minute per user
RATE_LIMIT_REQUESTS=60

# Rate limit window (seconds)
RATE_LIMIT_WINDOW=60

# =============================================================================
# CORS (Cross-Origin Resource Sharing)
# =============================================================================
# Allowed origins (comma-separated, or * for all)
CORS_ORIGINS=http://localhost:3000

# =============================================================================
# INTERNATIONALIZATION
# =============================================================================
# Default locale
DEFAULT_LOCALE=en

# Supported locales (comma-separated)
SUPPORTED_LOCALES=en,de

# =============================================================================
# FEATURE FLAGS
# =============================================================================
# Enable document generation
FEATURE_DOC_GENERATION=true

# Enable chat export
FEATURE_CHAT_EXPORT=true

# Enable analytics dashboard
FEATURE_ANALYTICS=true

# =============================================================================
# MONITORING (Optional)
# =============================================================================
# Sentry DSN for error tracking
SENTRY_DSN=

# Enable performance monitoring
ENABLE_PERFORMANCE_MONITORING=false
